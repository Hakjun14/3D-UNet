{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import  transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Labeling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Labeling, self).__init__()\n",
    "        \n",
    "        def max_pooling_3d():\n",
    "            return nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "        self.init = max_pooling_3d()\n",
    "    \n",
    "    def forward(self, x):\n",
    "       # Down sampling\n",
    "        out = self.init(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv_block_3d(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm3d(out_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),)\n",
    "\n",
    "\n",
    "        def conv_trans_block_3d(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose3d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm3d(out_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),)\n",
    "\n",
    "\n",
    "        def max_pooling_3d():\n",
    "            return nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "\n",
    "        def conv_block_2_3d(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                conv_block_3d(in_channels, out_channels),\n",
    "                nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm3d(out_channels),)\n",
    "\n",
    "#         def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "#             layers = []\n",
    "#             layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "#                                  kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "#                                  bias=bias)]\n",
    "#             layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "#             layers += [nn.ReLU()]\n",
    "\n",
    "#             cbr = nn.Sequential(*layers) # *으로 list unpacking \n",
    "\n",
    "#             return cbr\n",
    "        \n",
    "    ######Define layers\n",
    "        \n",
    "        # Down sampling\n",
    "        self.init = max_pooling_3d()\n",
    "        self.down_1 = conv_block_2_3d(in_channels=1, out_channels=4)\n",
    "        self.pool_1 = max_pooling_3d()\n",
    "        self.down_2 = conv_block_2_3d(in_channels=4, out_channels=8)\n",
    "        self.pool_2 = max_pooling_3d()\n",
    "        self.down_3 = conv_block_2_3d(in_channels=8, out_channels=16)\n",
    "        self.pool_3 = max_pooling_3d()\n",
    "        self.down_4 = conv_block_2_3d(in_channels=16, out_channels=32)\n",
    "        self.pool_4 = max_pooling_3d()\n",
    "        self.down_5 = conv_block_2_3d(in_channels=32, out_channels=64)\n",
    "        self.pool_5 = max_pooling_3d()\n",
    "        \n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = conv_block_2_3d(in_channels=64, out_channels=128)\n",
    "\n",
    "        \n",
    "        # Up sampling\n",
    "        self.trans_1 = conv_trans_block_3d(in_channels=128, out_channels=128)\n",
    "        self.up_1 = conv_block_2_3d(in_channels=192, out_channels=64)\n",
    "        self.trans_2 = conv_trans_block_3d(in_channels=64, out_channels=64)\n",
    "        self.up_2 = conv_block_2_3d(in_channels=96, out_channels=32)\n",
    "        self.trans_3 = conv_trans_block_3d(in_channels=32, out_channels=32)\n",
    "        self.up_3 = conv_block_2_3d(in_channels=48, out_channels=16)\n",
    "        self.trans_4 = conv_trans_block_3d(in_channels=16, out_channels=16)\n",
    "        self.up_4 = conv_block_2_3d(in_channels=24, out_channels=8)\n",
    "        self.trans_5 = conv_trans_block_3d(in_channels=8, out_channels=8)\n",
    "        self.up_5 = conv_block_2_3d(in_channels=12, out_channels=4)\n",
    "        \n",
    "        \n",
    "        # Output\n",
    "        self.out = conv_block_3d(in_channels=4, out_channels=1)\n",
    "        \n",
    "    #forwarding\n",
    "    def forward(self, x):\n",
    "       # Down sampling\n",
    "        init = self.init(x)\n",
    "        down_1 = self.down_1(init) # -> [1, 4, 128, 128, 128]\n",
    "        pool_1 = self.pool_1(down_1) # -> [1, 4, 64, 64, 64]\n",
    "\n",
    "        down_2 = self.down_2(pool_1) # -> [1, 8, 64, 64, 64]\n",
    "        pool_2 = self.pool_2(down_2) # -> [1, 8, 32, 32, 32]\n",
    "\n",
    "        down_3 = self.down_3(pool_2) # -> [1, 16, 32, 32, 32]\n",
    "        pool_3 = self.pool_3(down_3) # -> [1, 16, 16, 16, 16]\n",
    "\n",
    "        down_4 = self.down_4(pool_3) # -> [1, 32, 16, 16, 16]\n",
    "        pool_4 = self.pool_4(down_4) # -> [1, 32, 8, 8, 8]\n",
    "\n",
    "        down_5 = self.down_5(pool_4) # -> [1, 64, 8, 8, 8]\n",
    "        pool_5 = self.pool_5(down_5) # -> [1, 64, 4, 4, 4]\n",
    "\n",
    "        # Bridge\n",
    "        bridge = self.bridge(pool_5) # -> [1, 128, 4, 4, 4]\n",
    "       \n",
    "        # Up sampling\n",
    "        trans_1 = self.trans_1(bridge) # -> [1, 128, 8, 8, 8]\n",
    "        concat_1 = torch.cat([trans_1, down_5], dim=1) # -> [1, 192, 8, 8, 8]\n",
    "        up_1 = self.up_1(concat_1) # -> [1, 64, 8, 8, 8]\n",
    "\n",
    "        trans_2 = self.trans_2(up_1) # -> [1, 64, 16, 16, 16]\n",
    "        concat_2 = torch.cat([trans_2, down_4], dim=1) # -> [1, 96, 16, 16, 16]\n",
    "        up_2 = self.up_2(concat_2) # -> [1, 32, 16, 16, 16]\n",
    "   \n",
    "        trans_3 = self.trans_3(up_2) # -> [1, 32, 32, 32, 32]\n",
    "        concat_3 = torch.cat([trans_3, down_3], dim=1) # -> [1, 48, 32, 32, 32]\n",
    "        up_3 = self.up_3(concat_3) # -> [1, 16, 32, 32, 32]\n",
    "      \n",
    "        trans_4 = self.trans_4(up_3) # -> [1, 16, 64, 64, 64]\n",
    "        concat_4 = torch.cat([trans_4, down_2], dim=1) # -> [1, 24, 64, 64, 64]\n",
    "        up_4 = self.up_4(concat_4) # -> [1, 8, 64, 64, 64]\n",
    "\n",
    "        trans_5 = self.trans_5(up_4) # -> [1, 8, 128, 128, 128]\n",
    "        concat_5 = torch.cat([trans_5, down_1], dim=1) # -> [1, 12, 128, 128, 128]\n",
    "        up_5 = self.up_5(concat_5) # -> [1, 4, 128, 128, 128]\n",
    "      \n",
    "        # Output\n",
    "        out = self.out(up_5) # -> [1, 3, 128, 128, 128]\n",
    "        return out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        lst_data = os.listdir(self.data_dir)\n",
    "        \n",
    "        # 문자열 검사해서 'label'이 있으면 True \n",
    "        # 문자열 검사해서 'train'이 있으면 True\n",
    "        lst_label = [f for f in lst_data if f.startswith('label')] \n",
    "        lst_input = [f for f in lst_data if f.startswith('train')] \n",
    "        \n",
    "        lst_label.sort()\n",
    "        lst_input.sort()\n",
    "        self.lst_label = lst_label\n",
    "        self.lst_input = lst_input\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lst_label)\n",
    "    \n",
    "    # 데이터 load 파트\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        Dim_size=np.array((1024,1024,62),dtype=np.int)\n",
    "        \n",
    "        f = io.imread(os.path.join(self.data_dir, self.lst_label[index]))\n",
    "        label=np.array(f)\n",
    "        \n",
    "        g = io.imread(os.path.join(self.data_dir, self.lst_input[index]))\n",
    "        inputs=np.array(g)\n",
    "    \n",
    "        \n",
    "        # normalize, 이미지는 0~255 값을 가지고 있어 이를 0~1사이로 scaling\n",
    "        #label = label/255.0, label은 어차피 1, input은 최대값을 기준으로 normalize\n",
    "        inputs = inputs/np.max(inputs)\n",
    "        label = label.astype(np.float32)\n",
    "        inputs = inputs.astype(np.float32) \n",
    "\n",
    "        \n",
    "        # 인풋 데이터 차원이 2이면, 채널 축을 추가해줘야한다. \n",
    "        # 파이토치 인풋 format (batch, 채널, z, 행, 열)\n",
    "        \n",
    "        if label.ndim == 3:\n",
    "            label = label[:,:,:,np.newaxis]    #파이토치 인풋 포맷을 보고도 맨 뒤에 새로운 축을 생성하는 이유는 다음 class에서 확인하기\n",
    "        if inputs.ndim == 3:  \n",
    "            inputs = inputs[:,:,:,np.newaxis] \n",
    "        \n",
    "        data = {'input':inputs, 'label':label}\n",
    "\n",
    "        # transform에 할당된 class 들이 호출되면서 __call__ 함수 실행\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "    \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "        label, inputs = data['label'], data['input']\n",
    "   \n",
    "        # numpy와 tensor의 배열 차원 순서가 다르다. \n",
    "        # numpy : (행, 열, 채널)\n",
    "        # tensor : (채널, 행, 열)\n",
    "        # 따라서 위 순서에 맞춰 transpose\n",
    "        \n",
    "        label = label.transpose((3, 0, 1, 2)).astype(np.float32) \n",
    "        inputs = inputs.transpose((3, 0, 1, 2)).astype(np.float32)\n",
    "        \n",
    "        # 이후 np를 tensor로 바꾸는 코드는 다음과 같이 간단하다.\n",
    "        data = {'label': torch.from_numpy(label), 'input': torch.from_numpy(inputs)}\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 하이퍼 파라미터 설정\n",
    "lr = 1e-3\n",
    "batch_size = 1\n",
    "num_epoch = 50\n",
    "\n",
    "data_dir = './data'\n",
    "ckpt_dir = './ckpt12313123'\n",
    "log_dir = './log'\n",
    "res_dir = './result'\n",
    "\n",
    "patience = 1000\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 적용해서 데이터 셋 불러오기\n",
    "#transform = transforms.Compose(transforms.Normalize(0.5, 0.5), ToTensor())\n",
    "dataset_train = Dataset(data_dir=os.path.join(data_dir,'train'),transform=ToTensor())\n",
    "\n",
    "# 불러온 데이터셋, 배치 size줘서 DataLoader 해주기\n",
    "loader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle=True)\n",
    "# #for i, data in enumerate(loader_train,1):\n",
    "# #    print(data['label'].size())\n",
    "# # val set도 동일하게 진행\n",
    "# dataset_val = Dataset(data_dir=os.path.join(data_dir,'val'),transform = ToTensor())\n",
    "# loader_val = DataLoader(dataset_val, batch_size=1 , shuffle=True)\n",
    "\n",
    "# 네트워크 불러오기\n",
    "net = UNet().to(device) # device : cpu or gpu\n",
    "lala = Labeling().to(device)\n",
    "# loss 정의\n",
    "fn_loss = nn.MSELoss().to(device)\n",
    "\n",
    "# Optimizer 정의\n",
    "optim = torch.optim.Adam(net.parameters(), lr = lr ) \n",
    "\n",
    "# 기타 variables 설정\n",
    "num_train = len(dataset_train)\n",
    "#num_val = len(dataset_val)\n",
    "\n",
    "num_train_for_epoch = np.ceil(num_train/batch_size) # np.ceil : 소수점 반올림\n",
    "#num_val_for_epoch = np.ceil(num_val/batch_size)\n",
    "\n",
    "# 기타 function 설정\n",
    "fn_tonumpy = lambda x : x.to('cpu').detach().numpy().transpose(0,2,3,4,1) # device 위에 올라간 텐서를 detach 한 뒤 numpy로 변환\n",
    "fn_denorm = lambda x, mean, std : (x * std) + mean \n",
    "fn_classifier = lambda x :  1.0 * (x > 0.5)  # threshold 0.5 기준으로 indicator function으로 classifier 구현\n",
    "\n",
    "# Tensorbord\n",
    "#writer_train = SummaryWriter(log_dir = os.path.join(log_dir,'train'))\n",
    "#writer_val = SummaryWriter(log_dir = os.path.join(log_dir,'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
    "                            Default: 7\n",
    "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
    "                            Default: False\n",
    "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
    "                            Default: 0\n",
    "            path (str): checkpoint저장 경로\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save({'net':net.state_dict()},'%s'%(self.path))\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1641.90380859375\n",
      "epoch: 2, loss: 1621.94482421875\n",
      "epoch: 3, loss: 1598.786865234375\n",
      "epoch: 4, loss: 1587.117919921875\n",
      "epoch: 5, loss: 1579.581787109375\n",
      "epoch: 6, loss: 1575.038330078125\n",
      "epoch: 7, loss: 1572.3453369140625\n",
      "epoch: 8, loss: 1570.3753662109375\n",
      "epoch: 9, loss: 1569.4893798828125\n",
      "epoch: 10, loss: 1568.77001953125\n",
      "epoch: 11, loss: 1568.35888671875\n",
      "epoch: 12, loss: 1568.012451171875\n",
      "epoch: 13, loss: 1567.57080078125\n",
      "epoch: 14, loss: 1566.97314453125\n",
      "epoch: 15, loss: 1566.761962890625\n",
      "epoch: 16, loss: 1566.5440673828125\n",
      "epoch: 17, loss: 1566.208251953125\n",
      "epoch: 18, loss: 1565.9296875\n",
      "epoch: 19, loss: 1565.6724853515625\n",
      "epoch: 20, loss: 1565.43359375\n",
      "epoch: 21, loss: 1565.208740234375\n",
      "epoch: 22, loss: 1565.0322265625\n",
      "epoch: 23, loss: 1564.7764892578125\n",
      "epoch: 24, loss: 1564.499755859375\n",
      "epoch: 25, loss: 1564.32080078125\n",
      "epoch: 26, loss: 1564.0953369140625\n",
      "epoch: 27, loss: 1563.86181640625\n",
      "epoch: 28, loss: 1563.69189453125\n",
      "epoch: 29, loss: 1563.58984375\n",
      "epoch: 30, loss: 1564.3609619140625\n",
      "epoch: 31, loss: 1565.130615234375\n",
      "epoch: 32, loss: 1564.9461669921875\n",
      "epoch: 33, loss: 1564.2208251953125\n",
      "epoch: 34, loss: 1564.733642578125\n",
      "epoch: 35, loss: 1564.162841796875\n",
      "epoch: 36, loss: 1563.719482421875\n",
      "epoch: 37, loss: 1563.754150390625\n",
      "epoch: 38, loss: 1563.5311279296875\n",
      "epoch: 39, loss: 1563.08349609375\n",
      "epoch: 40, loss: 1562.7452392578125\n",
      "epoch: 41, loss: 1562.785888671875\n",
      "epoch: 42, loss: 1562.6343994140625\n",
      "epoch: 43, loss: 1562.276611328125\n",
      "epoch: 44, loss: 1562.018798828125\n",
      "epoch: 45, loss: 1561.964599609375\n",
      "epoch: 46, loss: 1561.86865234375\n",
      "epoch: 47, loss: 1561.6083984375\n",
      "epoch: 48, loss: 1561.365478515625\n",
      "epoch: 49, loss: 1561.2398681640625\n",
      "epoch: 50, loss: 1561.11328125\n"
     ]
    }
   ],
   "source": [
    "# 네트워크 저장하기\n",
    "# train을 마친 네트워크 저장 \n",
    "# net : 네트워크 파라미터, optim  두개를 dict 형태로 저장\n",
    "def save(ckpt_dir,net,optim,epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    torch.save({'net':net.state_dict(),'optim':optim.state_dict()},'%s/model_epoch%d.pth'%(ckpt_dir,epoch))\n",
    "\n",
    "# 네트워크 불러오기\n",
    "def load(ckpt_dir,net,optim):\n",
    "    if not os.path.exists(ckpt_dir): # 저장된 네트워크가 없다면 인풋을 그대로 반환\n",
    "        epoch = 0\n",
    "        return net, optim, epoch\n",
    "    \n",
    "    ckpt_lst = os.listdir(ckpt_dir) # ckpt_dir 아래 있는 모든 파일 리스트를 받아온다\n",
    "    ckpt_lst.sort(key = lambda f : int(''.join(filter(str,isdigit,f))))\n",
    "\n",
    "    dict_model = torch.load('%s/%s' % (ckpt_dir,ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
    "\n",
    "    return net,optim,epoch\n",
    "\n",
    "#early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
    "\n",
    "# 네트워크 학습시키기\n",
    "start_epoch = 0\n",
    "net, optim, start_epoch = load(ckpt_dir = ckpt_dir, net = net, optim = optim) # 저장된 네트워크 불러오기\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch+1,num_epoch +1):\n",
    "    net.train()\n",
    "    #loss_arr = []\n",
    "\n",
    "    for batch, data in enumerate(loader_train,1): # 1은 뭐니 > index start point\n",
    "        # forward\n",
    "        label = data['label'].to(device)   # 데이터 device로 올리기  \n",
    "        label_fin = lala(label)\n",
    "        inputs = data['input'].to(device)\n",
    "        output = net(inputs) \n",
    "        #plt.imshow(index[0,0,:,:], cmap='gray')\n",
    "\n",
    "        # backward\n",
    "        optim.zero_grad()  # gradient 초기화\n",
    "        loss = fn_loss(output, label_fin)  # output과 label 사이의 loss 계산\n",
    "        loss.backward() # gradient backpropagation\n",
    "        optim.step() # backpropa 된 gradient를 이용해서 각 layer의 parameters update\n",
    "\n",
    "        # save loss\n",
    "        print('epoch: {}, loss: {}'.format(epoch,loss.item()))\n",
    "        #loss_arr += [loss.item()]\n",
    "\n",
    "        # tensorbord에 결과값들 저정하기\n",
    "        label = fn_tonumpy(label)\n",
    "        inputs = fn_tonumpy(fn_denorm(inputs,0.5,0.5))\n",
    "        output = fn_tonumpy(fn_classifier(output))\n",
    "\n",
    "#         writer_train.add_image('label', label, num_train_for_epoch * (epoch - 1) + batch, dataformats='NHWC')\n",
    "#         writer_train.add_image('input', inputs, num_train_for_epoch * (epoch - 1) + batch, dataformats='NHWC')\n",
    "#         writer_train.add_image('output', output, num_train_for_epoch * (epoch - 1) + batch, dataformats='NHWC')\n",
    "\n",
    "#     writer_train.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "\n",
    "    \n",
    "#     # validation\n",
    "#     with torch.no_grad(): # validation 이기 때문에 backpropa 진행 x, 학습된 네트워크가 정답과 얼마나 가까운지 loss만 계산\n",
    "#         net.eval() # 네트워크를 evaluation 용으로 선언\n",
    "#         loss_arr = []\n",
    "\n",
    "#         for batch, data in enumerate(loader_val,1):\n",
    "#             # forward\n",
    "#             label = data['label'].to(device)\n",
    "#             inputs = data['input'].to(device)\n",
    "#             output = net(inputs)\n",
    "\n",
    "#             # loss \n",
    "#             loss = fn_loss(fn_classifier(output),label)\n",
    "#             loss_arr += [loss.item()]     \n",
    "#             print('valid : epoch %04d / %04d | Batch %04d \\ %f | Loss %f'%(epoch,num_epoch,batch,num_val_for_epoch,np.mean(loss_arr)))\n",
    "\n",
    "#             # Tensorboard 저장하기\n",
    "#             label = fn_tonumpy(label)\n",
    "#             inputs = fn_tonumpy(fn_denorm(inputs, mean=0.5, std=0.5))\n",
    "#             output = fn_tonumpy(fn_classifier(output))\n",
    "\n",
    "#             writer_val.add_image('label', label, num_val_for_epoch * (epoch - 1) + batch, dataformats='NHWC')\n",
    "#             writer_val.add_image('input', inputs, num_val_for_epoch * (epoch - 1) + batch, dataformats='NHWC')\n",
    "#             writer_val.add_image('output', output, num_val_for_epoch * (epoch - 1) + batch, dataformats='NHWC')\n",
    "\n",
    "#         writer_val.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "        \n",
    "#         early_stopping(np.mean(loss_arr), net)\n",
    "\n",
    "#         if early_stopping.early_stop:\n",
    "#             print(\"Early stopping\")\n",
    "#             break\n",
    "            \n",
    "        # epoch이 끝날때 마다 네트워크 저장\n",
    "    save(ckpt_dir=ckpt_dir, net = net, optim = optim, epoch = epoch)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "# writer_train.close()\n",
    "# writer_val.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Failed to interpret file './data/train/label_16_03.tif' as a pickle\n",
    "#무슨 뜻인지 1시간 정도 고민했는데, image file이 numpy형태로 변환이 안돼서 그런게 아닐까하는 생각을 했다.\n",
    "#transform이 잘 안되고 있다. tif 파일을 넘파이 배열로 저장시켜야 하는데 그게 안되기 때문에 np.load가 안되고 있는 상황\n",
    "#transform 은 이상 없었음. 파일을 넘파이로 바꿔주니 잘 넘어감\n",
    "#넘어는 가는데 input size를 (1,512,512)로 설정해서 train을 하고자 하였지만 들어가는 size가 (4,1,512,512)가 된다. 이유 확인하자\n",
    "#input format은 이게 맞다. NotImplementedError가 나온건 내가 forward 메소드를 __init__안에다 정의해서 그렇다. \n",
    "#그러나 이젠 다른 에러가 나타났다. 맙소사\n",
    "#뭐였더라, crop 이 안됐었는데 nn.module 내에서 transforms.CenterCrop을 정의했던게 문제였다.\n",
    "#train은 성공, \n",
    "#cuda0 이면 tensor -> numpy 로 전환할 때 >>> x.detach().cpu().numpy() 를 해야 바뀐다. 쿠다 아니면 x.numpy()바로 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "#Let's test\n",
    "dict_model = torch.load('%s/%s' % (ckpt_dir,'model_epoch50.pth'))\n",
    "\n",
    "net.load_state_dict(dict_model['net'])\n",
    "cnt = 1\n",
    "# test set도 동일하게 진행\n",
    "dataset_test = Dataset(data_dir=os.path.join(data_dir,'test'),transform = ToTensor())\n",
    "#loader_test = DataLoader(dataset_test, batch_size=1 , shuffle=False)\n",
    "#for batch, data in enumerate(loader_test):\n",
    "x = dataset_test[0]['input']\n",
    "y = x.unsqueeze_(0)\n",
    "print(y.size())\n",
    "\n",
    "    # forward\n",
    "#    label = data['label'].to(device)\n",
    "inputs = y.to(device)\n",
    "output = net(inputs)\n",
    "\n",
    "output = fn_tonumpy(output)\n",
    "#output = 255*output.astype(np.uint8)\n",
    "io.imsave('prob_map4.tif',np.squeeze(output))\n",
    "#     loss = fn_loss(fn_classifier(output),label)\n",
    "#     acc = (fn_classifier(output) == label).float().sum()\n",
    "#     print(\"loss is %f \\n accuracy is %f \" %(loss,acc/(512*512)))\n",
    "\n",
    "# img.save('%s/%s/result%d.tif' %(data_dir,res_dir,cnt))\n",
    "# cnt += 1\n",
    "# plt.imshow(np.squeeze(output))#, interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa65c670090>\n"
     ]
    }
   ],
   "source": [
    "print(loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
